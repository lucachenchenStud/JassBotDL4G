{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e81b25c",
   "metadata": {},
   "source": [
    "# DL4G - Jass Introduction\n",
    "\n",
    "In this exercise we will look at some properties of the jass kit environment that can be used to develop your own jass agent.\n",
    "\n",
    "You will need to have numpy installed, as well as the jass-kit environment."
   ]
  },
  {
   "cell_type": "code",
   "id": "0d71e284",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T09:43:08.326018Z",
     "start_time": "2025-10-31T09:43:08.323155Z"
    }
   },
   "source": [
    "from jass.game.game_util import *\n",
    "from jass.game.game_sim import GameSim\n",
    "from jass.game.game_observation import GameObservation\n",
    "from jass.game.const import *\n",
    "from jass.game.rule_schieber import RuleSchieber\n",
    "from jass.agents.agent import Agent\n",
    "from jass.agents.agent_random_schieber import AgentRandomSchieber\n",
    "from jass.arena.arena import Arena\n"
   ],
   "outputs": [],
   "execution_count": 79
  },
  {
   "cell_type": "markdown",
   "id": "9d510b9e",
   "metadata": {},
   "source": [
    "Information about the cards is stored as one-hot encoded arrays, there are several tools available to access the information in the cards. \n",
    "\n",
    "Lets deal some random cards first."
   ]
  },
  {
   "cell_type": "code",
   "id": "19767850",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T09:43:08.341713Z",
     "start_time": "2025-10-31T09:43:08.336270Z"
    }
   },
   "source": [
    "# Lets set the seed of the random number generater, so that we get the same results\n",
    "np.random.seed(1)\n",
    "\n",
    "# This distributes the cards randomly among the 4 players.\n",
    "hands = deal_random_hand()\n",
    "print(hands.shape)\n",
    "print(hands)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 36)\n",
      "[[0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 0 0 0 1 1 1 0 0 0 1 0]\n",
      " [0 0 1 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 1 1 0 0 1]\n",
      " [1 1 0 0 0 1 0 0 1 1 0 1 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "execution_count": 80
  },
  {
   "cell_type": "code",
   "id": "dcd87887",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T09:43:08.358444Z",
     "start_time": "2025-10-31T09:43:08.355178Z"
    }
   },
   "source": [
    "# There is an entry for each player, to access the cards of the first player\n",
    "cards = hands[0,:]\n",
    "print(cards)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 0 0 0 1 1 1 0 0 0 1 0]\n"
     ]
    }
   ],
   "execution_count": 81
  },
  {
   "cell_type": "code",
   "id": "486c3664",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T09:43:08.379115Z",
     "start_time": "2025-10-31T09:43:08.375999Z"
    }
   },
   "source": [
    "# This should be 9 cards\n",
    "assert(cards.sum() == 9)\n",
    "\n",
    "# The cards can be converted to other formats for easier reading or processing\n",
    "print(convert_one_hot_encoded_cards_to_str_encoded_list(cards))\n",
    "\n",
    "# Each card is encoded as a value between 0 and 35.\n",
    "print(convert_one_hot_encoded_cards_to_int_encoded_list(cards))\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[np.str_('DJ'), np.str_('H6'), np.str_('SK'), np.str_('SJ'), np.str_('S9'), np.str_('CK'), np.str_('CQ'), np.str_('CJ'), np.str_('C7')]\n",
      "[3, 17, 19, 21, 23, 28, 29, 30, 34]\n"
     ]
    }
   ],
   "execution_count": 82
  },
  {
   "cell_type": "code",
   "id": "89294107",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T09:43:08.397853Z",
     "start_time": "2025-10-31T09:43:08.394893Z"
    }
   },
   "source": [
    "# There is a method to count colors too\n",
    "colors = count_colors(cards)\n",
    "print(colors)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 3 4]\n"
     ]
    }
   ],
   "execution_count": 83
  },
  {
   "cell_type": "markdown",
   "id": "04f591d7",
   "metadata": {},
   "source": [
    "There is a common jass \"rule\" to select trump, when you have the \"Puur\" (Jack of trump) and 3 or more other cards of the same color. \n",
    "\n",
    "Task 1: Write a function that returns an array of 4 values that contains a 1 for each color that fulfills the rule or 0 otherwise, i.e. [0 0 0 0] is returned, if you do not have any color with Jack and 3 other cards.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "92845f51",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T09:43:08.418097Z",
     "start_time": "2025-10-31T09:43:08.415047Z"
    }
   },
   "source": [
    "def havePuurWithFour(hand: np.ndarray) -> np.ndarray:\n",
    "    result = np.zeros(4, dtype=int)\n",
    "    jack_index = 3  # because your order is [A, K, Q, J, 10, 9, 8, 7, 6]\n",
    "\n",
    "    for color in range(4):\n",
    "        start = color * 9\n",
    "        end = start + 9\n",
    "        suit_cards = hand[start:end]\n",
    "\n",
    "        has_puur = suit_cards[jack_index] == 1\n",
    "        num_cards = np.sum(suit_cards)\n",
    "\n",
    "        if has_puur and num_cards >= 4:\n",
    "            result[color] = 1\n",
    "\n",
    "    return result\n"
   ],
   "outputs": [],
   "execution_count": 84
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T09:43:08.434897Z",
     "start_time": "2025-10-31T09:43:08.431761Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(convert_one_hot_encoded_cards_to_str_encoded_list(cards))\n",
    "print(count_colors(cards))\n",
    "print(havePuurWithFour(cards))"
   ],
   "id": "ec3029af51a4abc4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[np.str_('DJ'), np.str_('H6'), np.str_('SK'), np.str_('SJ'), np.str_('S9'), np.str_('CK'), np.str_('CQ'), np.str_('CJ'), np.str_('C7')]\n",
      "[1 1 3 4]\n",
      "[0 0 0 1]\n"
     ]
    }
   ],
   "execution_count": 85
  },
  {
   "cell_type": "code",
   "id": "b1bb875a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T09:43:08.453378Z",
     "start_time": "2025-10-31T09:43:08.450434Z"
    }
   },
   "source": [
    "assert (havePuurWithFour(cards) == [0, 0, 0, 1]).all()\n",
    "cards_2 = hands[1,:]\n",
    "assert (havePuurWithFour(cards_2) == [0, 0, 0, 0]).all()"
   ],
   "outputs": [],
   "execution_count": 86
  },
  {
   "cell_type": "markdown",
   "id": "48371ec4",
   "metadata": {},
   "source": [
    "Another possibility to select trump is by assigning a value to each card, depending on whether the color is trump or not. This table is from the Maturawork of Daniel Graf from 2009: \"Jassen auf Basis der Spieltheorie\"."
   ]
  },
  {
   "cell_type": "code",
   "id": "01b078f3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T09:43:08.472488Z",
     "start_time": "2025-10-31T09:43:08.469442Z"
    }
   },
   "source": [
    "# Score for each card of a color from Ace to 6\n",
    "\n",
    "# score if the color is trump\n",
    "trump_score = [15, 10, 7, 25, 6, 19, 5, 5, 5]\n",
    "# score if the color is not trump\n",
    "no_trump_score = [9, 7, 5, 2, 1, 0, 0, 0, 0]\n",
    "# score if obenabe is selected (all colors)\n",
    "obenabe_score = [14, 10, 8, 7, 5, 0, 5, 0, 0,]\n",
    "# score if uneufe is selected (all colors)\n",
    "uneufe_score = [0, 2, 1, 1, 5, 5, 7, 9, 11]"
   ],
   "outputs": [],
   "execution_count": 87
  },
  {
   "cell_type": "markdown",
   "id": "ddd00b63",
   "metadata": {},
   "source": [
    "Task 2: Implement a function that evaluates a hand that is given as a list of 9 cards and with a given trump value and returns a score depending on the table above. For example the score of our hand ['DJ', 'H6', 'SK', 'SJ', 'S9', 'CK', 'CQ', 'CJ', 'C7'] when Club is trump should be:\n",
    "\n",
    "2 + 0 + 7 + 2 + 0 + 10 + 7 + 25 + 5 = 58\n",
    "\n",
    "while the score is 70 if Spade is selected, which is better as you have both the jack and the nine.\n",
    "\n",
    "You can use the arrays offset_of_card and color_of_card to get the offset (Ace, King, etc.) and color of a card."
   ]
  },
  {
   "cell_type": "code",
   "id": "63297245",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T09:43:08.483260Z",
     "start_time": "2025-10-31T09:43:08.479714Z"
    }
   },
   "source": [
    "def calculate_trump_selection_score(cards, trump: int) -> int:\n",
    "    \"\"\"\n",
    "    cards: list of 9 integer-encoded cards (0–35)\n",
    "    trump: int 0–3 representing the trump color (0=Clubs, 1=Spades, 2=Hearts, 3=Diamonds)\n",
    "    returns: total score (int)\n",
    "    \"\"\"\n",
    "    trump_score = [15, 10, 7, 25, 6, 19, 5, 5, 5]\n",
    "    no_trump_score = [9, 7, 5, 2, 1, 0, 0, 0, 0]\n",
    "\n",
    "    score = 0\n",
    "\n",
    "    for card in cards:\n",
    "        color = color_of_card[card]\n",
    "        offset = offset_of_card[card]\n",
    "\n",
    "        if color == trump:\n",
    "            score += trump_score[offset]\n",
    "        else:\n",
    "            score += no_trump_score[offset]\n",
    "\n",
    "    return score\n",
    "    "
   ],
   "outputs": [],
   "execution_count": 88
  },
  {
   "cell_type": "code",
   "id": "0ae55a9d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T09:43:08.491468Z",
     "start_time": "2025-10-31T09:43:08.488861Z"
    }
   },
   "source": [
    "card_list = convert_one_hot_encoded_cards_to_int_encoded_list(cards)\n",
    "assert calculate_trump_selection_score(card_list, CLUBS) == 58\n",
    "assert calculate_trump_selection_score(card_list, SPADES) == 70"
   ],
   "outputs": [],
   "execution_count": 89
  },
  {
   "cell_type": "markdown",
   "id": "4ec0d316",
   "metadata": {},
   "source": [
    "## Agents\n",
    "\n",
    "In order to play a game you have to program an agent that decides on the action. For that you have to override the methods action_trump and action_play_card.\n",
    "\n",
    "Task 3: Use the function implemented above to select the best trump value. If the calculated trump value is below a threshold (for example let us take 68, as suggested in the work by Daniel Graf) you should \"Schiebe\", i.e. pass to your partner if you are still allowed to do that.\n",
    "\n",
    "The game observation allows you to access the information about your card, and if you are the first or second player to select trump.\n",
    "\n",
    "For playing a card, we just take a random action."
   ]
  },
  {
   "cell_type": "code",
   "id": "2c8a0c7e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T09:43:08.507633Z",
     "start_time": "2025-10-31T09:43:08.503635Z"
    }
   },
   "source": [
    "class MyAgent(Agent):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # we need a rule object to determine the valid cards\n",
    "        self._rule = RuleSchieber()\n",
    "        \n",
    "    def action_trump(self, obs: GameObservation) -> int:\n",
    "        \"\"\"\n",
    "        Determine trump action for the given observation\n",
    "        Args:\n",
    "            obs: the game observation, it must be in a state for trump selection\n",
    "\n",
    "        Returns:\n",
    "            selected trump as encoded in jass.game.const or jass.game.const.PUSH\n",
    "        \"\"\"\n",
    "       # get your cards as int encoded list\n",
    "        cards = convert_one_hot_encoded_cards_to_int_encoded_list(obs.hand)\n",
    "\n",
    "        # compute scores for all four trumps\n",
    "        scores = [calculate_trump_selection_score(cards, trump) for trump in range(4)]\n",
    "        best_trump = int(np.argmax(scores))\n",
    "        best_score = scores[best_trump]\n",
    "\n",
    "        # threshold logic: 68 suggested by Daniel Graf\n",
    "        if best_score < 68 and obs.trump is None:\n",
    "            return PUSH  # pass to partner\n",
    "        else:\n",
    "            return best_trump\n",
    "        \n",
    "\n",
    "    def action_play_card(self, obs: GameObservation) -> int:\n",
    "        \"\"\"\n",
    "        Determine the card to play.\n",
    "\n",
    "        Args:\n",
    "            obs: the game observation\n",
    "\n",
    "        Returns:\n",
    "            the card to play, int encoded as defined in jass.game.const\n",
    "        \"\"\"\n",
    "        valid_cards = self._rule.get_valid_cards_from_obs(obs)\n",
    "        # we use the global random number generator here\n",
    "        return np.random.choice(np.flatnonzero(valid_cards))\n",
    "    \n",
    "    "
   ],
   "outputs": [],
   "execution_count": 90
  },
  {
   "cell_type": "markdown",
   "id": "1f5b305a",
   "metadata": {},
   "source": [
    "We can use the game simulation to play a game. We will use that to test our implementation, and then use the arena class to play against other agents"
   ]
  },
  {
   "cell_type": "code",
   "id": "91df4f83",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T09:43:08.516710Z",
     "start_time": "2025-10-31T09:43:08.513720Z"
    }
   },
   "source": [
    "rule = RuleSchieber()\n",
    "game = GameSim(rule=rule)\n",
    "agent = MyAgent()\n",
    "\n",
    "np.random.seed(1)\n",
    "game.init_from_cards(hands=deal_random_hand(), dealer=NORTH)"
   ],
   "outputs": [],
   "execution_count": 91
  },
  {
   "cell_type": "code",
   "id": "1f177a07",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T09:43:08.527801Z",
     "start_time": "2025-10-31T09:43:08.525243Z"
    }
   },
   "source": [
    "obs = game.get_observation()"
   ],
   "outputs": [],
   "execution_count": 92
  },
  {
   "cell_type": "code",
   "id": "768c5cce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T09:43:08.538491Z",
     "start_time": "2025-10-31T09:43:08.535331Z"
    }
   },
   "source": [
    "cards = convert_one_hot_encoded_cards_to_str_encoded_list(obs.hand)\n",
    "print(cards)\n",
    "trump = agent.action_trump(obs)\n",
    "assert trump == HEARTS"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[np.str_('DA'), np.str_('DK'), np.str_('D9'), np.str_('D6'), np.str_('HA'), np.str_('HQ'), np.str_('HJ'), np.str_('H8'), np.str_('H7')]\n"
     ]
    }
   ],
   "execution_count": 93
  },
  {
   "cell_type": "code",
   "id": "9ccc8b9e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T09:43:08.557557Z",
     "start_time": "2025-10-31T09:43:08.555161Z"
    }
   },
   "source": [
    "# tell the simulation the selected trump\n",
    "game.action_trump(trump)"
   ],
   "outputs": [],
   "execution_count": 94
  },
  {
   "cell_type": "code",
   "id": "eb8c2956",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T09:43:08.577141Z",
     "start_time": "2025-10-31T09:43:08.572309Z"
    }
   },
   "source": [
    "# play the game to the end and print the result\n",
    "while not game.is_done():\n",
    "    game.action_play_card(agent.action_play_card(game.get_observation()))\n",
    "\n",
    "print(game.state.points)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 10 147]\n"
     ]
    }
   ],
   "execution_count": 95
  },
  {
   "cell_type": "markdown",
   "id": "b33d069e",
   "metadata": {},
   "source": [
    "Another possibility to test agents locally is to use the arena. Let us play 100 games against the Random Agent and see if our trump methods makes any difference.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "07c99989",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T09:43:08.594324Z",
     "start_time": "2025-10-31T09:43:08.591268Z"
    }
   },
   "source": [
    "arena = Arena(nr_games_to_play=100)\n",
    "arena.set_players(MyAgent(), AgentRandomSchieber(), MyAgent(), AgentRandomSchieber())"
   ],
   "outputs": [],
   "execution_count": 96
  },
  {
   "cell_type": "code",
   "id": "ba8464b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T09:43:08.820594Z",
     "start_time": "2025-10-31T09:43:08.607528Z"
    }
   },
   "source": [
    "arena.play_all_games()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[........................................]  100/ 100 games played\n"
     ]
    }
   ],
   "execution_count": 97
  },
  {
   "cell_type": "code",
   "id": "05179929",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T09:43:08.829213Z",
     "start_time": "2025-10-31T09:43:08.826323Z"
    }
   },
   "source": [
    "print(arena.points_team_0.sum(), arena.points_team_1.sum())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8778.0 6922.0\n"
     ]
    }
   ],
   "execution_count": 98
  },
  {
   "cell_type": "markdown",
   "id": "dd500485",
   "metadata": {},
   "source": [
    "Now you can continue with a rule based implemenation of the card play. Also look at the flask implementation of the service to see how you can get your agent online."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T09:43:08.848296Z",
     "start_time": "2025-10-31T09:43:08.842751Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from jass.game.rule_schieber import RuleSchieber\n",
    "import numpy as np\n",
    "\n",
    "class MyRuleBasedAgent(MyAgent):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self._rule = RuleSchieber()\n",
    "\n",
    "    def action_play_card(self, obs):\n",
    "        valid_cards = self._rule.get_valid_cards_from_obs(obs)\n",
    "        valid_indices = np.flatnonzero(valid_cards)\n",
    "\n",
    "        trump = obs.trump\n",
    "        current_trick = obs.current_trick\n",
    "        first_card = next((c for c in current_trick if c != -1), None)\n",
    "\n",
    "        # Helper: get color of any card\n",
    "        def get_color(card):\n",
    "            return color_of_card[card]\n",
    "\n",
    "        # If you are first in trick → just play highest card\n",
    "        if first_card is None:\n",
    "            return self._play_highest(valid_indices)\n",
    "\n",
    "        first_color = get_color(first_card)\n",
    "\n",
    "        # Separate your valid cards by color\n",
    "        same_color = [c for c in valid_indices if get_color(c) == first_color]\n",
    "        trump_cards = [c for c in valid_indices if get_color(c) == trump]\n",
    "        others = [c for c in valid_indices if c not in same_color + trump_cards]\n",
    "\n",
    "        # 1️⃣ If you can follow color → play highest in that color\n",
    "        if same_color:\n",
    "            return self._play_highest(same_color)\n",
    "\n",
    "        # 2️⃣ If you cannot follow color but have trump → play the lowest trump (save strong ones)\n",
    "        if trump_cards:\n",
    "            return self._play_lowest(trump_cards)\n",
    "\n",
    "        # 3️⃣ Otherwise → throw lowest non-trump card\n",
    "        return self._play_lowest(others)\n",
    "\n",
    "    def _play_highest(self, cards):\n",
    "        best_card = cards[0]\n",
    "        best_rank = 10\n",
    "        for c in cards:\n",
    "            offset = offset_of_card[c]\n",
    "            if offset < best_rank:  # smaller offset = stronger rank\n",
    "                best_card = c\n",
    "                best_rank = offset\n",
    "        return best_card\n",
    "\n",
    "    def _play_lowest(self, cards):\n",
    "        worst_card = cards[0]\n",
    "        worst_rank = -1\n",
    "        for c in cards:\n",
    "            offset = offset_of_card[c]\n",
    "            if offset > worst_rank:  # larger offset = weaker card\n",
    "                worst_card = c\n",
    "                worst_rank = offset\n",
    "        return worst_card"
   ],
   "id": "a027569fc98f8ac9",
   "outputs": [],
   "execution_count": 99
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T09:43:09.065549Z",
     "start_time": "2025-10-31T09:43:08.856972Z"
    }
   },
   "cell_type": "code",
   "source": [
    "arena = Arena(nr_games_to_play=100)\n",
    "arena.set_players(MyRuleBasedAgent(), AgentRandomSchieber(), MyRuleBasedAgent(), AgentRandomSchieber())\n",
    "arena.play_all_games()\n",
    "\n",
    "print(\"Team 0:\", arena.points_team_0.sum(), \"Team 1:\", arena.points_team_1.sum())\n"
   ],
   "id": "ca2b0249b7e130d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[........................................]  100/ 100 games played\n",
      "Team 0: 8473.0 Team 1: 7227.0\n"
     ]
    }
   ],
   "execution_count": 100
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T09:43:09.077678Z",
     "start_time": "2025-10-31T09:43:09.069761Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class MyAdvancedRuleBasedAgent(MyRuleBasedAgent):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self._rule = RuleSchieber()\n",
    "\n",
    "    def action_play_card(self, obs):\n",
    "        valid_cards = self._rule.get_valid_cards_from_obs(obs)\n",
    "        valid_indices = np.flatnonzero(valid_cards)\n",
    "        trump = obs.trump\n",
    "        current_trick = obs.current_trick\n",
    "        first_card = next((c for c in current_trick if c != -1), None)\n",
    "\n",
    "        def get_color(card):\n",
    "            return color_of_card[card]\n",
    "\n",
    "        def get_rank(card):\n",
    "            return offset_of_card[card]\n",
    "\n",
    "        # ---- Case 1: You start the trick ----\n",
    "        if first_card is None:\n",
    "            # Prefer to start with your highest non-trump card (save trump)\n",
    "            non_trump_cards = [c for c in valid_indices if get_color(c) != trump]\n",
    "            if non_trump_cards:\n",
    "                return self._play_highest(non_trump_cards)\n",
    "            return self._play_lowest(valid_indices)\n",
    "\n",
    "        # ---- Case 2: Follow color if possible ----\n",
    "        first_color = get_color(first_card)\n",
    "        same_color = [c for c in valid_indices if get_color(c) == first_color]\n",
    "        trump_cards = [c for c in valid_indices if get_color(c) == trump]\n",
    "        others = [c for c in valid_indices if c not in same_color + trump_cards]\n",
    "\n",
    "        if same_color:\n",
    "            # Try to win the trick if possible\n",
    "            winning_card = self._get_winning_card(current_trick, trump)\n",
    "            if winning_card is None or get_color(winning_card) != first_color:\n",
    "                # Trick currently led by non-follow card, try to win\n",
    "                return self._play_highest(same_color)\n",
    "            else:\n",
    "                # Trick currently led by same color, only play higher if possible\n",
    "                higher = [c for c in same_color if get_rank(c) < get_rank(winning_card)]\n",
    "                if higher:\n",
    "                    return self._play_highest(higher)\n",
    "                # Can't win, play lowest\n",
    "                return self._play_lowest(same_color)\n",
    "\n",
    "        # ---- Case 3: Cannot follow color ----\n",
    "        # Check if partner is currently winning the trick\n",
    "        partner_pos = (obs.player + 2) % 4\n",
    "        partner_card = current_trick[partner_pos]\n",
    "        winning_card = self._get_winning_card(current_trick, trump)\n",
    "        partner_winning = (partner_card != -1 and winning_card == partner_card)\n",
    "\n",
    "        if partner_winning:\n",
    "            # Don't waste trump, discard lowest non-trump\n",
    "            if others:\n",
    "                return self._play_lowest(others)\n",
    "            return self._play_lowest(trump_cards)\n",
    "\n",
    "        # Partner not winning\n",
    "        if trump_cards:\n",
    "            # Avoid wasting the Puur if possible (Jack of trump)\n",
    "            puur_index = self._get_puur_index(trump)\n",
    "            non_puur_trumps = [c for c in trump_cards if c != puur_index]\n",
    "            if non_puur_trumps:\n",
    "                return self._play_lowest(non_puur_trumps)\n",
    "            return self._play_lowest(trump_cards)\n",
    "\n",
    "        # Otherwise, discard weakest card\n",
    "        return self._play_lowest(others)\n",
    "\n",
    "    # --- Helpers ---\n",
    "    def _play_highest(self, cards):\n",
    "        return min(cards, key=lambda c: offset_of_card[c])  # lower offset = higher rank\n",
    "\n",
    "    def _play_lowest(self, cards):\n",
    "        return max(cards, key=lambda c: offset_of_card[c])  # higher offset = weaker card\n",
    "\n",
    "    def _get_puur_index(self, trump_color):\n",
    "        \"\"\"Return the integer card index of the Jack of trump.\"\"\"\n",
    "        return trump_color * 9 + 3  # because [A,K,Q,J,10,9,8,7,6] -> Jack=3\n",
    "\n",
    "    def _get_winning_card(self, current_trick, trump):\n",
    "        \"\"\"Return the current winning card in the trick.\"\"\"\n",
    "        played = [c for c in current_trick if c != -1]\n",
    "        if not played:\n",
    "            return None\n",
    "        first_color = color_of_card[played[0]]\n",
    "\n",
    "        def rank_value(card):\n",
    "            color = color_of_card[card]\n",
    "            offset = offset_of_card[card]\n",
    "            # Simple numeric order: trump beats others\n",
    "            base = 100 - offset  # A small numeric advantage for high ranks\n",
    "            if color == trump:\n",
    "                base += 100\n",
    "            elif color != first_color:\n",
    "                base -= 100\n",
    "            return base\n",
    "\n",
    "        return max(played, key=rank_value)\n"
   ],
   "id": "4648e31d6b242c64",
   "outputs": [],
   "execution_count": 101
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T09:43:09.271489Z",
     "start_time": "2025-10-31T09:43:09.083944Z"
    }
   },
   "cell_type": "code",
   "source": [
    "arena = Arena(nr_games_to_play=100)\n",
    "arena.set_players(MyAdvancedRuleBasedAgent(), MyRuleBasedAgent(),\n",
    "                  MyAdvancedRuleBasedAgent(), MyRuleBasedAgent())\n",
    "arena.play_all_games()\n",
    "\n",
    "print(\"Team 0:\", arena.points_team_0.sum(), \"Team 1:\", arena.points_team_1.sum())\n"
   ],
   "id": "17adbffbb0e485b0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[........................................]  100/ 100 games played\n",
      "Team 0: 8198.0 Team 1: 7502.0\n"
     ]
    }
   ],
   "execution_count": 102
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T09:43:09.283254Z",
     "start_time": "2025-10-31T09:43:09.275576Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class MyMemoryAgent(MyAdvancedRuleBasedAgent):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self._rule = RuleSchieber()\n",
    "        self._played_cards = set()  # store integer card IDs that were played\n",
    "\n",
    "    def action_play_card(self, obs):\n",
    "        # --- Update memory with all cards visible in this trick ---\n",
    "        self._update_memory(obs)\n",
    "\n",
    "        valid_cards = self._rule.get_valid_cards_from_obs(obs)\n",
    "        valid_indices = np.flatnonzero(valid_cards)\n",
    "        trump = obs.trump\n",
    "        current_trick = obs.current_trick\n",
    "        first_card = next((c for c in current_trick if c != -1), None)\n",
    "\n",
    "        def get_color(card): return color_of_card[card]\n",
    "        def get_rank(card): return offset_of_card[card]\n",
    "\n",
    "        # --- If you are starting the trick ---\n",
    "        if first_card is None:\n",
    "            # Prefer to play a color where many of its cards are already gone\n",
    "            remaining_by_color = self._count_remaining_by_color()\n",
    "            # pick the color with fewest cards left in the deck\n",
    "            color_to_play = min(remaining_by_color, key=remaining_by_color.get)\n",
    "            color_cards = [c for c in valid_indices if get_color(c) == color_to_play]\n",
    "            if color_cards:\n",
    "                return self._play_highest(color_cards)\n",
    "            return self._play_lowest(valid_indices)\n",
    "\n",
    "        # --- Follow-color logic remains the same ---\n",
    "        first_color = get_color(first_card)\n",
    "        same_color = [c for c in valid_indices if get_color(c) == first_color]\n",
    "        trump_cards = [c for c in valid_indices if get_color(c) == trump]\n",
    "        others = [c for c in valid_indices if c not in same_color + trump_cards]\n",
    "\n",
    "        # Follow color if possible\n",
    "        if same_color:\n",
    "            return self._play_best_in_color(same_color, current_trick, trump)\n",
    "\n",
    "        # No same color: check partner winning\n",
    "        partner_pos = (obs.player + 2) % 4\n",
    "        partner_card = current_trick[partner_pos]\n",
    "        winning_card = self._get_winning_card(current_trick, trump)\n",
    "        partner_winning = (partner_card != -1 and winning_card == partner_card)\n",
    "\n",
    "        if partner_winning:\n",
    "            # discard lowest from a color already depleted\n",
    "            safe_colors = self._get_depleted_colors()\n",
    "            safe_discards = [c for c in others if get_color(c) in safe_colors]\n",
    "            if safe_discards:\n",
    "                return self._play_lowest(safe_discards)\n",
    "            return self._play_lowest(others or trump_cards)\n",
    "\n",
    "        # Play trump if not partner winning\n",
    "        if trump_cards:\n",
    "            puur_index = self._get_puur_index(trump)\n",
    "            non_puur_trumps = [c for c in trump_cards if c != puur_index]\n",
    "            if non_puur_trumps:\n",
    "                return self._play_lowest(non_puur_trumps)\n",
    "            return self._play_lowest(trump_cards)\n",
    "\n",
    "        # Otherwise discard weakest\n",
    "        return self._play_lowest(others)\n",
    "\n",
    "    # --- MEMORY HELPERS ---\n",
    "    def _update_memory(self, obs):\n",
    "        \"\"\"Add all visible cards from tricks and table to memory.\"\"\"\n",
    "        # Current trick cards\n",
    "        for c in obs.current_trick:\n",
    "            if c != -1:\n",
    "                self._played_cards.add(c)\n",
    "        # Previous tricks\n",
    "        for t in obs.tricks:\n",
    "            for c in t:\n",
    "                if c != -1:\n",
    "                    self._played_cards.add(c)\n",
    "\n",
    "    def _count_remaining_by_color(self):\n",
    "        \"\"\"Count how many cards remain unseen per color.\"\"\"\n",
    "        counts = {0: 0, 1: 0, 2: 0, 3: 0}\n",
    "        for card in range(36):\n",
    "            if card not in self._played_cards:\n",
    "                color = color_of_card[card]\n",
    "                counts[color] += 1\n",
    "        return counts\n",
    "\n",
    "    def _get_depleted_colors(self):\n",
    "        \"\"\"Return colors with few cards remaining (likely void in others).\"\"\"\n",
    "        counts = self._count_remaining_by_color()\n",
    "        return [c for c, count in counts.items() if count <= 4]\n",
    "\n",
    "    def _play_best_in_color(self, cards, current_trick, trump):\n",
    "        \"\"\"Decide whether to play high or low within the color.\"\"\"\n",
    "        winning_card = self._get_winning_card(current_trick, trump)\n",
    "        first_color = color_of_card[current_trick[0]]\n",
    "        # if no one played a higher card yet, play high\n",
    "        if winning_card is None or color_of_card[winning_card] != first_color:\n",
    "            return self._play_highest(cards)\n",
    "        else:\n",
    "            higher = [c for c in cards if offset_of_card[c] < offset_of_card[winning_card]]\n",
    "            if higher:\n",
    "                return self._play_highest(higher)\n",
    "            return self._play_lowest(cards)\n"
   ],
   "id": "ebcadcb650fb49ec",
   "outputs": [],
   "execution_count": 103
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T09:43:09.524133Z",
     "start_time": "2025-10-31T09:43:09.289419Z"
    }
   },
   "cell_type": "code",
   "source": [
    "arena = Arena(nr_games_to_play=100)\n",
    "arena.set_players(MyMemoryAgent(), AgentRandomSchieber(),\n",
    "                  MyMemoryAgent(), AgentRandomSchieber())\n",
    "arena.play_all_games()\n",
    "\n",
    "print(\"Team 0:\", arena.points_team_0.sum(), \"Team 1:\", arena.points_team_1.sum())\n"
   ],
   "id": "90e1deaa246665e5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[........................................]  100/ 100 games played\n",
      "Team 0: 9034.0 Team 1: 6666.0\n"
     ]
    }
   ],
   "execution_count": 104
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T09:43:09.539779Z",
     "start_time": "2025-10-31T09:43:09.529071Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import copy\n",
    "import numpy as np\n",
    "\n",
    "# --- Helpers you likely already have in your notebook ---\n",
    "# team of a player: 0 for players {0,2}, 1 for players {1,3}\n",
    "def team_of(player_id: int) -> int:\n",
    "    return 0 if player_id % 2 == 0 else 1\n",
    "\n",
    "# Get valid moves from full information.\n",
    "# If your RuleSchieber exposes \"get_valid_cards_from_state\", use that.\n",
    "# Otherwise, ask the GameSim directly for valid moves.\n",
    "def get_valid_moves(rule, game) -> np.ndarray:\n",
    "    valid_mask = rule.get_valid_cards_from_obs(game.get_observation())\n",
    "    moves = np.flatnonzero(valid_mask)\n",
    "    return moves[:2]  # try fewer for speed\n",
    "\n",
    "# Play a card on a cloned game and return the clone\n",
    "def play_on_clone(game, card):\n",
    "    \"\"\"\n",
    "    Create a lightweight clone of GameSim by deep-copying it once,\n",
    "    play 'card' on the copy, and return the new GameSim.\n",
    "    \"\"\"\n",
    "    # Deepcopy the full object – slow but works for property-based design\n",
    "    g2 = copy.deepcopy(game)\n",
    "    # Execute the card on the cloned state\n",
    "    g2.action_play_card(card)\n",
    "    return g2\n",
    "\n",
    "# Did the current trick finish? (4 cards played)\n",
    "def trick_finished(game) -> bool:\n",
    "    \"\"\"\n",
    "    Return True if 4 cards have been played in the current trick.\n",
    "    Handles None-type current_trick for start of game/trick.\n",
    "    \"\"\"\n",
    "    trick = game.state.current_trick\n",
    "    if trick is None:\n",
    "        return False  # no trick yet, so not finished\n",
    "    return all(c != -1 for c in trick)\n",
    "\n",
    "# Points of the *last completed* trick, split by teams.\n",
    "# If RuleSchieber exposes a direct method, use it. Otherwise, use state fields.\n",
    "def last_trick_points_by_team(game, rule):\n",
    "    # In Schieber, points are accumulated in state.points during scoring, but we need just this trick.\n",
    "    # Workaround approach:\n",
    "    # - When trick finishes, RuleSchieber internally scores and adds to state.points.\n",
    "    # - So: before simulating a playout branch, capture points; after trick completion, diff the points.\n",
    "    # We implement this by taking the delta externally in minimax (see below).\n",
    "    return tuple(game.state.points)  # return full cumulative points for delta computation\n",
    "\n",
    "# Returns current trick leader’s winning card and winner player index.\n",
    "# Most rule versions have something like rule.winning_card / rule.winner_of_trick.\n",
    "def current_trick_winner(rule, game):\n",
    "    trick = game.state.current_trick\n",
    "    if any(c == -1 for c in trick):\n",
    "        return None, None\n",
    "    # If available:\n",
    "    # winner = rule.winner_of_trick(trick, game.state.trump, game.state.first_player)\n",
    "    # return trick[winner_index_in_trick], winner_global_player_id\n",
    "    # Fallback: many rule APIs provide a direct winner; if not, you can compute, but that’s not needed for scoring here.\n",
    "    return None, None\n",
    "\n",
    "# Order moves (optional): try higher trump first, then high same-color, then others.\n",
    "def move_order_heuristic(moves):\n",
    "    # Simple: identity. You can add smarter ordering if you want pruning to work better.\n",
    "    return moves\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Minimax for CURRENT TRICK ONLY\n",
    "# -----------------------------\n",
    "def choose_card_minimax_current_trick(game, rule):\n",
    "    \"\"\"\n",
    "    Cheating: picks the card that maximizes points in THIS trick only.\n",
    "    \"\"\"\n",
    "    root_player = game.state.player  # player to act now\n",
    "    root_team = team_of(root_player)\n",
    "\n",
    "    # Snapshot team points now – we’ll compute trick-only points as a delta after trick completes.\n",
    "    base_points = tuple(game.state.points)\n",
    "\n",
    "    best_value = -1e9\n",
    "    best_card = None\n",
    "\n",
    "    for card in move_order_heuristic(get_valid_moves(rule, game)):\n",
    "        g2 = play_on_clone(game, card)\n",
    "        value = _minimax_trick(g2, rule, root_team, base_points)\n",
    "        if value > best_value:\n",
    "            best_value = value\n",
    "            best_card = card\n",
    "\n",
    "    return best_card\n",
    "\n",
    "MAX_DEPTH = 10  # just to be safe\n",
    "\n",
    "def _minimax_trick(game, rule, root_team, base_points, depth=0):\n",
    "    if depth > MAX_DEPTH:\n",
    "        return 0  # stop evaluating further\n",
    "\n",
    "    trick = game.state.current_trick\n",
    "    if trick is None:\n",
    "        return 0\n",
    "    if all(c != -1 for c in trick):\n",
    "        pts_after = tuple(game.state.points)\n",
    "        trick_delta_team0 = pts_after[0] - base_points[0]\n",
    "        trick_delta_team1 = pts_after[1] - base_points[1]\n",
    "        return trick_delta_team0 - trick_delta_team1 if root_team == 0 else trick_delta_team1 - trick_delta_team0\n",
    "\n",
    "    player_to_act = game.state.player\n",
    "    maximizing = (team_of(player_to_act) == root_team)\n",
    "    best = -1e9 if maximizing else 1e9\n",
    "\n",
    "    for card in get_valid_moves(rule, game):\n",
    "        g2 = play_on_clone(game, card)\n",
    "        val = _minimax_trick(g2, rule, root_team, base_points, depth+1)\n",
    "        if maximizing:\n",
    "            best = max(best, val)\n",
    "        else:\n",
    "            best = min(best, val)\n",
    "    return best\n",
    "\n",
    "\n",
    "# -------------------------------------------\n",
    "# Minimax over N COMPLETE TRICKS (with alpha-beta)\n",
    "# -------------------------------------------\n",
    "def choose_card_minimax_n_tricks(game, rule, n_tricks=2, use_alpha_beta=True):\n",
    "    \"\"\"\n",
    "    Cheating: choose card maximizing points over the next n complete tricks.\n",
    "    Uses alpha-beta pruning by default.\n",
    "    \"\"\"\n",
    "    root_player = game.state.player\n",
    "    root_team = team_of(root_player)\n",
    "\n",
    "    best_value = -1e9\n",
    "    best_card = None\n",
    "\n",
    "    alpha, beta = -1e9, 1e9\n",
    "\n",
    "    for card in move_order_heuristic(get_valid_moves(rule, game)):\n",
    "        g2 = play_on_clone(game, card)\n",
    "        val = _minimax_n_tricks(\n",
    "            g2, rule, root_team, n_tricks=n_tricks,\n",
    "            alpha=alpha, beta=beta, use_alpha_beta=use_alpha_beta\n",
    "        )\n",
    "        if val > best_value:\n",
    "            best_value = val\n",
    "            best_card = card\n",
    "        if use_alpha_beta:\n",
    "            alpha = max(alpha, val)\n",
    "\n",
    "    return best_card\n",
    "\n",
    "\n",
    "def _minimax_n_tricks(game, rule, root_team, n_tricks, alpha, beta, use_alpha_beta):\n",
    "    # Base cases:\n",
    "    if n_tricks <= 0:\n",
    "        # Value is current total point difference\n",
    "        pts0, pts1 = game.state.points\n",
    "        return (pts0 - pts1) if root_team == 0 else (pts1 - pts0)\n",
    "\n",
    "    # If current trick finished, just continue with one fewer trick to simulate\n",
    "    if trick_finished(game):\n",
    "        # Advance to next trick automatically handled by GameSim;\n",
    "        # points already added into game.state.points.\n",
    "        return _minimax_n_tricks(game, rule, root_team, n_tricks - 1, alpha, beta, use_alpha_beta)\n",
    "\n",
    "    player_to_act = game.state.player\n",
    "    maximizing = (team_of(player_to_act) == root_team)\n",
    "\n",
    "    if maximizing:\n",
    "        best = -1e9\n",
    "        for card in move_order_heuristic(get_valid_moves(rule, game)):\n",
    "            g2 = play_on_clone(game, card)\n",
    "            val = _minimax_n_tricks(g2, rule, root_team, n_tricks, alpha, beta, use_alpha_beta)\n",
    "            best = max(best, val)\n",
    "            if use_alpha_beta:\n",
    "                alpha = max(alpha, val)\n",
    "                if beta <= alpha:\n",
    "                    break  # beta cut\n",
    "        return best\n",
    "    else:\n",
    "        best = 1e9\n",
    "        for card in move_order_heuristic(get_valid_moves(rule, game)):\n",
    "            g2 = play_on_clone(game, card)\n",
    "            val = _minimax_n_tricks(g2, rule, root_team, n_tricks, alpha, beta, use_alpha_beta)\n",
    "            best = min(best, val)\n",
    "            if use_alpha_beta:\n",
    "                beta = min(beta, val)\n",
    "                if beta <= alpha:\n",
    "                    break  # alpha cut\n",
    "        return best\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# A cheating Minimax Agent\n",
    "# --------------------------\n",
    "# This agent expects to be given the FULL game (GameSim) at selection time,\n",
    "# so you can use it in your own loop like:\n",
    "# best = MinimaxTrickAgent(rule).select_card(game)  # cheating\n",
    "class MinimaxTrickAgent:\n",
    "    def __init__(self, rule, n_tricks=1, use_alpha_beta=True):\n",
    "        self.rule = rule\n",
    "        self.n_tricks = n_tricks\n",
    "        self.use_alpha_beta = use_alpha_beta\n",
    "\n",
    "    def select_card(self, game):\n",
    "        if self.n_tricks == 1:\n",
    "            return choose_card_minimax_current_trick(game, self.rule)\n",
    "        else:\n",
    "            return choose_card_minimax_n_tricks(game, self.rule, n_tricks=self.n_tricks, use_alpha_beta=self.use_alpha_beta)\n"
   ],
   "id": "ce55d1505879d6aa",
   "outputs": [],
   "execution_count": 105
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T09:43:15.288135Z",
     "start_time": "2025-10-31T09:43:09.546439Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Example: play one trick (or the whole game loop) with cheating Minimax.\n",
    "rule = RuleSchieber()\n",
    "game = GameSim(rule=rule)\n",
    "np.random.seed(1)\n",
    "game.init_from_cards(hands=deal_random_hand(), dealer=NORTH)\n",
    "\n",
    "agent = MinimaxTrickAgent(rule, n_tricks=2)  # current-trick greedy\n",
    "# OR: agent = MinimaxTrickAgent(rule, n_tricks=2, use_alpha_beta=True)\n",
    "\n",
    "# If you want to simulate a full game using this agent for your seat only:\n",
    "while not game.is_done():\n",
    "    if game.state.player == 0:  # say you're player 0\n",
    "        card = agent.select_card(game)   # cheating: full info from 'game'\n",
    "    else:\n",
    "        # Opponents/partner can be random or your other agents\n",
    "        valid = np.flatnonzero(rule.get_valid_cards_from_obs(game.get_observation()))\n",
    "        card = np.random.choice(valid)\n",
    "    game.action_play_card(card)\n",
    "\n",
    "print(\"Final points:\", game.state.points)\n"
   ],
   "id": "70fd63b627c61fc8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final points: [97 60]\n"
     ]
    }
   ],
   "execution_count": 106
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T09:43:15.681588Z",
     "start_time": "2025-10-31T09:43:15.563341Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import time\n",
    "\n",
    "rule = RuleSchieber()\n",
    "game = GameSim(rule=rule)\n",
    "game.init_from_cards(hands=deal_random_hand(), dealer=NORTH)\n",
    "\n",
    "agent = MinimaxTrickAgent(rule, n_tricks=1)\n",
    "\n",
    "start = time.time()\n",
    "card = agent.select_card(game)\n",
    "print(\"Chosen card:\", card, \"took\", round(time.time() - start, 2), \"seconds\")\n"
   ],
   "id": "c8b61b5af722cd2b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chosen card: 0 took 0.11 seconds\n"
     ]
    }
   ],
   "execution_count": 107
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T09:43:15.695573Z",
     "start_time": "2025-10-31T09:43:15.687205Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import copy, math, numpy as np\n",
    "\n",
    "# -------- Helpers (reuse your earlier ones) --------\n",
    "def team_of(pid: int) -> int:\n",
    "    return 0 if pid % 2 == 0 else 1\n",
    "\n",
    "def get_valid_moves(rule, game) -> np.ndarray:\n",
    "    mask = rule.get_valid_cards_from_obs(game.get_observation())\n",
    "    return np.flatnonzero(mask)\n",
    "\n",
    "def trick_finished(game) -> bool:\n",
    "    trick = game.state.current_trick\n",
    "    if trick is None:\n",
    "        return False\n",
    "    return all(c != -1 for c in trick)\n",
    "\n",
    "def clone_and_play(game, card):\n",
    "    g2 = copy.deepcopy(game)\n",
    "    g2.action_play_card(card)\n",
    "    return g2\n",
    "\n",
    "def simulate_random_until(rule, game, n_tricks=1):\n",
    "    \"\"\"Simulate randomly until current trick ends (n_tricks=1) or for n_tricks completed.\"\"\"\n",
    "    tricks_left = n_tricks\n",
    "    start_tricks = game.state.nr_tricks\n",
    "    while True:\n",
    "        if trick_finished(game):\n",
    "            # one trick completed -> engine will start next trick on next play\n",
    "            if game.state.nr_tricks >= start_tricks + tricks_left:\n",
    "                break\n",
    "        if game.is_done():\n",
    "            break\n",
    "        moves = get_valid_moves(rule, game)\n",
    "        if len(moves) == 0:\n",
    "            break\n",
    "        card = np.random.choice(moves)\n",
    "        game.action_play_card(card)\n",
    "\n",
    "def value_from_points(points, root_team: int) -> int:\n",
    "    t0, t1 = points\n",
    "    return (t0 - t1) if root_team == 0 else (t1 - t0)\n",
    "\n",
    "# ----------------- MCTS Node -----------------\n",
    "class MCTSNode:\n",
    "    __slots__ = (\"parent\", \"children\", \"N\", \"W\", \"Q\", \"untried\")\n",
    "\n",
    "    def __init__(self, parent=None, untried=None):\n",
    "        self.parent = parent\n",
    "        self.children = {}      # action -> node\n",
    "        self.N = 0              # visits\n",
    "        self.W = 0.0            # total value\n",
    "        self.Q = 0.0            # mean value\n",
    "        self.untried = list(untried) if untried is not None else []\n",
    "\n",
    "    def uct_select(self, c=1.414):\n",
    "        \"\"\"Select child with maximal UCT.\"\"\"\n",
    "        log_Np = math.log(self.N + 1e-9)\n",
    "        def uct(a_node):\n",
    "            a, node = a_node\n",
    "            return node.Q + c * math.sqrt(log_Np / (node.N + 1e-9))\n",
    "        return max(self.children.items(), key=uct)\n",
    "\n",
    "    def expand(self, action, child_untried):\n",
    "        child = MCTSNode(parent=self, untried=child_untried)\n",
    "        self.children[action] = child\n",
    "        if action in self.untried:\n",
    "            self.untried.remove(action)\n",
    "        return child\n",
    "\n",
    "    def backprop(self, value):\n",
    "        n = self\n",
    "        while n is not None:\n",
    "            n.N += 1\n",
    "            n.W += value\n",
    "            n.Q = n.W / n.N\n",
    "            n = n.parent\n",
    "\n",
    "# --------------- Cheating MCTS agent ---------------\n",
    "class MCTSAgentCheating:\n",
    "    def __init__(self, rule, iterations=1000, c=1.414, horizon_tricks=1):\n",
    "        self.rule = rule\n",
    "        self.iterations = iterations\n",
    "        self.c = c\n",
    "        self.horizon_tricks = horizon_tricks\n",
    "\n",
    "    def select_card(self, game):\n",
    "        root_team = team_of(game.state.player)\n",
    "        root = MCTSNode(untried=get_valid_moves(self.rule, game))\n",
    "\n",
    "        if len(root.untried) == 1:\n",
    "            return root.untried[0]\n",
    "\n",
    "        for _ in range(self.iterations):\n",
    "            # Selection\n",
    "            node = root\n",
    "            g = copy.deepcopy(game)\n",
    "            # traverse down using UCT while no untried and children exist\n",
    "            while not node.untried and node.children:\n",
    "                action, node = node.uct_select(self.c)\n",
    "                g.action_play_card(action)\n",
    "\n",
    "            # Expansion\n",
    "            if node.untried:\n",
    "                a = np.random.choice(node.untried)\n",
    "                g.action_play_card(a)\n",
    "                child_untried = get_valid_moves(self.rule, g)\n",
    "                node = node.expand(a, child_untried)\n",
    "\n",
    "            # Simulation\n",
    "            simulate_random_until(self.rule, g, n_tricks=self.horizon_tricks)\n",
    "\n",
    "            # Value (team diff from root perspective)\n",
    "            val = value_from_points(g.state.points, root_team)\n",
    "\n",
    "            # Backprop\n",
    "            node.backprop(val)\n",
    "\n",
    "        # Pick action with highest visit count (robust)\n",
    "        best_a = max(root.children.items(), key=lambda kv: kv[1].N)[0]\n",
    "        return best_a\n"
   ],
   "id": "47da9c858954b0d1",
   "outputs": [],
   "execution_count": 108
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T09:43:20.826038Z",
     "start_time": "2025-10-31T09:43:15.702426Z"
    }
   },
   "cell_type": "code",
   "source": [
    "rule = RuleSchieber()\n",
    "game = GameSim(rule=rule)\n",
    "np.random.seed(1)\n",
    "game.init_from_cards(hands=deal_random_hand(), dealer=NORTH)\n",
    "\n",
    "mcts = MCTSAgentCheating(rule, iterations=1500, c=1.2, horizon_tricks=1)  # trick MCTS\n",
    "# or horizon_tricks=2..3 for deeper impact\n",
    "\n",
    "while not game.is_done():\n",
    "    if game.state.player == 0:\n",
    "        card = mcts.select_card(game)\n",
    "    else:\n",
    "        valid = get_valid_moves(rule, game)\n",
    "        card = np.random.choice(valid)\n",
    "    game.action_play_card(card)\n",
    "\n",
    "print(\"Final points:\", game.state.points)\n"
   ],
   "id": "b1a364a5432358ab",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final points: [112  45]\n"
     ]
    }
   ],
   "execution_count": 109
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T09:43:21.108599Z",
     "start_time": "2025-10-31T09:43:21.101068Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ---- Utilities to reconstruct hidden hands consistent with observation ----\n",
    "def observed_played_cards(obs):\n",
    "    played = set()\n",
    "    for trick in obs.tricks:\n",
    "        for c in trick:\n",
    "            if c != -1:\n",
    "                played.add(c)\n",
    "    for c in obs.current_trick:\n",
    "        if c != -1:\n",
    "            played.add(c)\n",
    "    return played\n",
    "\n",
    "\n",
    "def sample_determinization(obs, rng=np.random):\n",
    "    \"\"\"Return a fully specified GameSim (full-information state) consistent with a GameObservation.\"\"\"\n",
    "    my_id = obs.player\n",
    "    my_hand = np.flatnonzero(obs.hand)  # cards in my hand\n",
    "\n",
    "    # --- 1. Collect played cards ---\n",
    "    played = set()\n",
    "    for trick in obs.tricks:\n",
    "        for c in trick:\n",
    "            if c != -1:\n",
    "                played.add(int(c))\n",
    "    for c in obs.current_trick:\n",
    "        if c != -1:\n",
    "            played.add(int(c))\n",
    "\n",
    "    all_cards = set(range(36))\n",
    "    remaining = list(all_cards - set(my_hand) - played)\n",
    "    rng.shuffle(remaining)\n",
    "\n",
    "    # --- 2. Count cards already played per player ---\n",
    "    cards_played_by = [0, 0, 0, 0]\n",
    "    # figure out which trick first player index to use\n",
    "    current_first_player = int(obs.trick_first_player[obs.nr_tricks])\n",
    "\n",
    "    for t_index, t in enumerate(obs.tricks):\n",
    "        first_p = int(obs.trick_first_player[t_index])\n",
    "        for i, c in enumerate(t):\n",
    "            if c != -1:\n",
    "                pid = (first_p + i) % 4\n",
    "                cards_played_by[pid] += 1\n",
    "\n",
    "    for i, c in enumerate(obs.current_trick):\n",
    "        if c != -1:\n",
    "            pid = (current_first_player + i) % 4\n",
    "            cards_played_by[pid] += 1\n",
    "\n",
    "    # --- 3. Determine how many cards each still needs ---\n",
    "    need = [9 - cards_played_by[p] for p in range(4)]\n",
    "    need[my_id] = len(my_hand)\n",
    "\n",
    "    # --- 4. Initialize hands (2D array) ---\n",
    "    cursor = 0\n",
    "    hands = np.zeros((4, 36), dtype=np.int8)\n",
    "    hands[my_id, my_hand] = 1\n",
    "    opp_ids = [p for p in range(4) if p != my_id]\n",
    "\n",
    "    for pid in opp_ids:\n",
    "        k = need[pid]\n",
    "        assign = remaining[cursor:cursor + k]\n",
    "        cursor += k\n",
    "        hands[pid, assign] = 1\n",
    "\n",
    "    # --- 5. Build GameSim with copied state ---\n",
    "    g = GameSim(rule=RuleSchieber())\n",
    "    s = g.state\n",
    "    s.hands = hands\n",
    "    s.player = obs.player\n",
    "    s.trump = obs.trump\n",
    "    s.points = np.array(obs.points, dtype=np.int16)\n",
    "    s.dealer = obs.dealer\n",
    "    s.nr_tricks = obs.nr_tricks\n",
    "    s.nr_played_cards = obs.nr_played_cards\n",
    "    s.nr_cards_in_trick = obs.nr_cards_in_trick\n",
    "    s.trick_first_player = np.array(obs.trick_first_player, dtype=np.int16)\n",
    "    s.trick_points = np.array(obs.trick_points, dtype=np.int16)\n",
    "    s.trick_winner = np.array(obs.trick_winner, dtype=np.int16)\n",
    "    s.current_trick = np.array(obs.current_trick, dtype=np.int16)\n",
    "    s.tricks = np.array(obs.tricks, dtype=np.int16)\n",
    "    s.forehand = obs.forehand\n",
    "    s.declared_trump = obs.declared_trump\n",
    "\n",
    "    return g\n",
    "\n",
    "# ---- Determinization wrapper ----\n",
    "class MCTSAgentDeterminized:\n",
    "    def __init__(self, iterations_per_det=300, n_dets=20, c=1.2, horizon_tricks=1):\n",
    "        self.iterations_per_det = iterations_per_det\n",
    "        self.n_dets = n_dets\n",
    "        self.c = c\n",
    "        self.horizon_tricks = horizon_tricks\n",
    "\n",
    "    def action_play_card(self, obs):\n",
    "        # aggregate visits over determinization runs\n",
    "        visit_counts = {}\n",
    "        for _ in range(self.n_dets):\n",
    "            g_det = sample_determinization(obs)\n",
    "            mcts = MCTSAgentCheating(RuleSchieber(),\n",
    "                                     iterations=self.iterations_per_det,\n",
    "                                     c=self.c,\n",
    "                                     horizon_tricks=self.horizon_tricks)\n",
    "            # one “select_card” without advancing original obs\n",
    "            a = mcts.select_card(g_det)\n",
    "            visit_counts[a] = visit_counts.get(a, 0) + 1\n",
    "\n",
    "        # choose action with most votes\n",
    "        best = max(visit_counts.items(), key=lambda kv: kv[1])[0]\n",
    "        return best\n"
   ],
   "id": "8e49c72306819aab",
   "outputs": [],
   "execution_count": 110
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T09:43:21.117331Z",
     "start_time": "2025-10-31T09:43:21.112806Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class ISMCTSAgent:\n",
    "    def __init__(self, iterations=2000, c=1.2, horizon_tricks=1):\n",
    "        self.iterations = iterations\n",
    "        self.c = c\n",
    "        self.horizon_tricks = horizon_tricks\n",
    "\n",
    "    def action_play_card(self, obs):\n",
    "        root_team = team_of(obs.player)\n",
    "        # Root node keyed by \"information set\" = empty history\n",
    "        root = MCTSNode(untried=self._valid_from_obs(obs))\n",
    "\n",
    "        # If only one legal move, play it\n",
    "        if len(root.untried) == 1:\n",
    "            return root.untried[0]\n",
    "\n",
    "        for _ in range(self.iterations):\n",
    "            # 1) Sample one determinization consistent with obs\n",
    "            g = sample_determinization(obs)\n",
    "\n",
    "            # 2) Selection/Expansion on a single open-loop tree\n",
    "            node = root\n",
    "            while not node.untried and node.children:\n",
    "                action, node = node.uct_select(self.c)\n",
    "                g.action_play_card(action)\n",
    "\n",
    "            if node.untried:\n",
    "                a = np.random.choice(node.untried)\n",
    "                g.action_play_card(a)\n",
    "                node = node.expand(a, self._valid_from_state(g))\n",
    "\n",
    "            # 3) Rollout\n",
    "            simulate_random_until(RuleSchieber(), g, self.horizon_tricks)\n",
    "\n",
    "            # 4) Backprop with value from this determinization\n",
    "            val = value_from_points(g.state.points, root_team)\n",
    "            node.backprop(val)\n",
    "\n",
    "        # robust child – highest visit count\n",
    "        return max(root.children.items(), key=lambda kv: kv[1].N)[0]\n",
    "\n",
    "    def _valid_from_obs(self, obs):\n",
    "        mask = RuleSchieber().get_valid_cards_from_obs(obs)\n",
    "        return np.flatnonzero(mask)\n",
    "\n",
    "    def _valid_from_state(self, game):\n",
    "        mask = RuleSchieber().get_valid_cards_from_obs(game.get_observation())\n",
    "        return np.flatnonzero(mask)\n"
   ],
   "id": "783d257ace3d4325",
   "outputs": [],
   "execution_count": 111
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T09:43:21.124296Z",
     "start_time": "2025-10-31T09:43:21.121132Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class AgentMCTSDeterminized(Agent):\n",
    "    def __init__(self, iterations_per_det=300, n_dets=10, c=1.2, horizon_tricks=1):\n",
    "        super().__init__()\n",
    "        self._rule = RuleSchieber()\n",
    "        self._core = MCTSAgentDeterminized(\n",
    "            iterations_per_det=iterations_per_det,\n",
    "            n_dets=n_dets,\n",
    "            c=c,\n",
    "            horizon_tricks=horizon_tricks\n",
    "        )\n",
    "\n",
    "    def action_trump(self, obs):\n",
    "        # Simple: never schiebe for testing (or random trump)\n",
    "        from jass.game.const import HEARTS\n",
    "        return HEARTS\n",
    "\n",
    "    def action_play_card(self, obs):\n",
    "        return self._core.action_play_card(obs)\n"
   ],
   "id": "6f2e03cab97816c1",
   "outputs": [],
   "execution_count": 112
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T09:43:21.131923Z",
     "start_time": "2025-10-31T09:43:21.128879Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class AgentISMCTS(Agent):\n",
    "    def __init__(self, iterations=2000, c=1.2, horizon_tricks=1):\n",
    "        super().__init__()\n",
    "        self._rule = RuleSchieber()\n",
    "        self._core = ISMCTSAgent(iterations=iterations, c=c, horizon_tricks=horizon_tricks)\n",
    "\n",
    "    def action_trump(self, obs):\n",
    "        from jass.game.const import HEARTS\n",
    "        return HEARTS\n",
    "\n",
    "    def action_play_card(self, obs):\n",
    "        return self._core.action_play_card(obs)"
   ],
   "id": "e8b91e511ae91d49",
   "outputs": [],
   "execution_count": 113
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T09:44:02.273489Z",
     "start_time": "2025-10-31T09:43:21.138175Z"
    }
   },
   "cell_type": "code",
   "source": [
    "arena = Arena(nr_games_to_play=2)\n",
    "arena.set_players(\n",
    "    AgentMCTSDeterminized(), AgentISMCTS(),\n",
    "    AgentMCTSDeterminized(), AgentISMCTS()\n",
    ")\n",
    "arena.play_all_games()\n",
    "\n",
    "print(\"Team0:\", arena.points_team_0.sum(), \"Team1:\", arena.points_team_1.sum())\n"
   ],
   "id": "b35a4e4a7bf88e02",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Team0: 175.0 Team1: 139.0\n"
     ]
    }
   ],
   "execution_count": 114
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T09:56:36.450641Z",
     "start_time": "2025-10-31T09:56:07.995808Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import importlib\n",
    "import jass.agents.agent_mlmcts\n",
    "import jass.agents.agent_mcts_determinized\n",
    "importlib.reload(jass.agents.agent_mlmcts)\n",
    "importlib.reload(jass.agents.agent_mcts_determinized)\n",
    "\n",
    "from jass.agents.agent_mlmcts import AgentMLMCTS, TrumpPredictor, MCTSAdapter\n",
    "from jass.agents.agent_mcts_determinized import MCTSAgentDeterminized\n",
    "from jass.arena.arena import Arena\n",
    "\n",
    "mcts = MCTSAgentDeterminized(iterations_per_det=50, n_dets=5)\n",
    "mcts_adapter = MCTSAdapter(mcts)\n",
    "trump_predictor = TrumpPredictor(\"jass/agents/trump_model.joblib\")\n",
    "bot = AgentMLMCTS(trump_predictor, mcts_adapter)\n",
    "\n",
    "arena = Arena(nr_games_to_play=5)\n",
    "arena.set_players(bot, AgentISMCTS(), bot, AgentISMCTS())\n",
    "arena.play_all_games()\n",
    "\n",
    "print(\"Team0:\", arena.points_team_0.sum(), \"Team1:\", arena.points_team_1.sum())"
   ],
   "id": "55a2c4df101e3257",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[........................................]    5/   5 games played\n",
      "Team0: 464.0 Team1: 321.0\n"
     ]
    }
   ],
   "execution_count": 127
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T12:48:34.821860Z",
     "start_time": "2025-10-31T12:48:34.813115Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import requests\n",
    "r = requests.post(\"http://10.155.121.147:5000/play\", json={\n",
    "    \"trump\": -1,\n",
    "    \"forehand\": 1,\n",
    "    \"hand\": [1,0,1,0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],\n",
    "    \"player\": 0\n",
    "})\n",
    "print(r.status_code, r.text)\n"
   ],
   "id": "a336909e2b309f47",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 {\"action\":5}\n",
      "\n"
     ]
    }
   ],
   "execution_count": 130
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "e62a42e14c370181"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
